{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ijT1UJe0msP",
        "outputId": "c797d012-d30f-4161-e2d7-7f98b9dc592a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Poetry\n",
            "0  aaÃ±kh se duur na ho dil se utar jÄ.egÄ \\nvaqt ...\n",
            "1  ÄshiqÄ« meÃ± 'mÄ«r' jaise á¸³hvÄb mat dekhÄ karo \\n...\n",
            "2  ab aur kyÄ kisÄ« se marÄsim baá¸ŒhÄ.eÃ± ham \\nye b...\n",
            "3  ab ke ham bichhá¸Œe to shÄyad kabhÄ« á¸³hvÄboÃ± meÃ± ...\n",
            "4  ab ke tajdÄ«d-e-vafÄ kÄ nahÄ«Ã± imkÄÃ± jÄnÄÃ± \\nyaa...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read only the \"Poetry\" column from the CSV file\n",
        "df = pd.read_csv(\"Roman-Urdu-Poetry.csv\", usecols=[\"Poetry\"])\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Function to remove Urdu punctuation and diacritics\n",
        "def remove_urdu_punctuation_and_diacritics(text):\n",
        "    if isinstance(text, str):\n",
        "        # Remove Urdu punctuation and diacritics\n",
        "        text = re.sub(r'[ØŒÛ”ØŸ!\"â€œâ€â€˜â€™Ø›\\.-]', '', text)  # Removes punctuation\n",
        "        return text\n",
        "    return text\n",
        "\n",
        "# Clean specific columns\n",
        "columns_to_clean = ['Poetry']\n",
        "\n",
        "for column in columns_to_clean:\n",
        "    df[column] = df[column].apply(remove_urdu_punctuation_and_diacritics)\n",
        "\n",
        "df.to_csv(\"Cleaned_Roman-Urdu-Poetry.csv\", index=False)\n",
        "\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKGCsVnp05WX",
        "outputId": "3964a8c9-08f7-435c-c4c6-2bc233a8f4ad"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Poetry\n",
            "0  aaÃ±kh se duur na ho dil se utar jÄegÄ \\nvaqt k...\n",
            "1  ÄshiqÄ« meÃ± 'mÄ«r' jaise á¸³hvÄb mat dekhÄ karo \\n...\n",
            "2  ab aur kyÄ kisÄ« se marÄsim baá¸ŒhÄeÃ± ham \\nye bh...\n",
            "3  ab ke ham bichhá¸Œe to shÄyad kabhÄ« á¸³hvÄboÃ± meÃ± ...\n",
            "4  ab ke tajdÄ«devafÄ kÄ nahÄ«Ã± imkÄÃ± jÄnÄÃ± \\nyaad ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Convert poetry to a list\n",
        "poetry_lines = df[\"Poetry\"].tolist()\n",
        "\n",
        "# Tokenizer to convert words into numerical form\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(poetry_lines)\n",
        "\n",
        "# Convert text into sequences\n",
        "sequences = tokenizer.texts_to_sequences(poetry_lines)\n",
        "\n",
        "# Define input (X) and output (Y) sequences\n",
        "input_sequences = []\n",
        "for seq in sequences:\n",
        "    for i in range(1, len(seq)):\n",
        "        input_sequences.append(seq[:i+1])\n",
        "\n",
        "# Padding sequences\n",
        "max_length = max(len(seq) for seq in input_sequences)\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_length, padding=\"pre\")\n",
        "\n",
        "# Split into X (input) and Y (output)\n",
        "X, Y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "\n",
        "# Convert Y into one-hot encoding\n",
        "Y = np.array(Y)  # Keep Y as integer labels\n",
        "\n",
        "print(\"Data prepared for LSTM training!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCTRpgGv071E",
        "outputId": "d4db7fa4-2d20-4cc6-ea1b-e2359fd7764f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data prepared for LSTM training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Split data into Training (80%) and Temporary Set (20%)\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the Temporary Set into Validation (10%) and Testing (10%)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Print dataset shapes\n",
        "print(\"Data successfully split!\")\n",
        "print(f\"Training Data: X_train = {X_train.shape}, Y_train = {Y_train.shape}\")\n",
        "print(f\"Validation Data: X_val = {X_val.shape}, Y_val = {Y_val.shape}\")\n",
        "print(f\"Test Data: X_test = {X_test.shape}, Y_test = {Y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5OFQj4o0-Ve",
        "outputId": "f965cb84-752f-4701-f260-c62a4520cba9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully split!\n",
            "Training Data: X_train = (124496, 433), Y_train = (124496,)\n",
            "Validation Data: X_val = (15562, 433), Y_val = (15562,)\n",
            "Test Data: X_test = (15563, 433), Y_test = (15563,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Step 1: Get Vocabulary Size\n",
        "vocab_size = np.max(X_train) + 1  # Largest token ID + 1\n",
        "\n",
        "# Step 2: Define the LSTM Model\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 100, input_length=X_train.shape[1]),  # Embedding layer\n",
        "    LSTM(150, return_sequences=True),  # First LSTM layer\n",
        "    LSTM(150),  # Second LSTM layer\n",
        "    Dense(150, activation=\"relu\"),  # Dense layer\n",
        "    Dense(vocab_size, activation=\"softmax\")  # Output layer\n",
        "])\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Step 4: Train the Model\n",
        "epochs = 55  # Adjust based on performance\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_val, Y_val),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Step 5: Save the Model\n",
        "model.save(\"lstm_poetry_model.h5\")\n",
        "print(\"Model trained and saved as 'lstm_poetry_model.h5'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyv5cvTE1A0V",
        "outputId": "c5024617-0762-4ab6-d3b1-33bd8a21efd2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 86ms/step - accuracy: 0.0415 - loss: 7.3163 - val_accuracy: 0.0419 - val_loss: 6.8869\n",
            "Epoch 2/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 85ms/step - accuracy: 0.0445 - loss: 6.6624 - val_accuracy: 0.0459 - val_loss: 6.9709\n",
            "Epoch 3/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 87ms/step - accuracy: 0.0518 - loss: 6.5301 - val_accuracy: 0.0547 - val_loss: 6.9744\n",
            "Epoch 4/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 88ms/step - accuracy: 0.0647 - loss: 6.3574 - val_accuracy: 0.0645 - val_loss: 7.0290\n",
            "Epoch 5/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 85ms/step - accuracy: 0.0753 - loss: 6.1868 - val_accuracy: 0.0659 - val_loss: 7.0826\n",
            "Epoch 6/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.0859 - loss: 6.0295 - val_accuracy: 0.0700 - val_loss: 7.1175\n",
            "Epoch 7/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.0954 - loss: 5.8814 - val_accuracy: 0.0734 - val_loss: 7.2046\n",
            "Epoch 8/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 86ms/step - accuracy: 0.1022 - loss: 5.7634 - val_accuracy: 0.0752 - val_loss: 7.3953\n",
            "Epoch 9/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 85ms/step - accuracy: 0.1107 - loss: 5.6352 - val_accuracy: 0.0749 - val_loss: 7.5136\n",
            "Epoch 10/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.1186 - loss: 5.4811 - val_accuracy: 0.0771 - val_loss: 7.6141\n",
            "Epoch 11/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 86ms/step - accuracy: 0.1261 - loss: 5.3565 - val_accuracy: 0.0779 - val_loss: 7.8481\n",
            "Epoch 12/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 86ms/step - accuracy: 0.1347 - loss: 5.2153 - val_accuracy: 0.0778 - val_loss: 8.1449\n",
            "Epoch 13/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 86ms/step - accuracy: 0.1430 - loss: 5.0860 - val_accuracy: 0.0787 - val_loss: 8.3838\n",
            "Epoch 14/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 86ms/step - accuracy: 0.1488 - loss: 4.9587 - val_accuracy: 0.0766 - val_loss: 8.7486\n",
            "Epoch 15/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 86ms/step - accuracy: 0.1554 - loss: 4.8270 - val_accuracy: 0.0767 - val_loss: 9.1629\n",
            "Epoch 16/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 85ms/step - accuracy: 0.1671 - loss: 4.6763 - val_accuracy: 0.0795 - val_loss: 9.6117\n",
            "Epoch 17/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.1728 - loss: 4.5648 - val_accuracy: 0.0750 - val_loss: 10.0630\n",
            "Epoch 18/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 86ms/step - accuracy: 0.1849 - loss: 4.4294 - val_accuracy: 0.0751 - val_loss: 10.5085\n",
            "Epoch 19/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 87ms/step - accuracy: 0.1987 - loss: 4.3230 - val_accuracy: 0.0731 - val_loss: 11.0286\n",
            "Epoch 20/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 86ms/step - accuracy: 0.2112 - loss: 4.2316 - val_accuracy: 0.0736 - val_loss: 11.4299\n",
            "Epoch 21/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 85ms/step - accuracy: 0.2248 - loss: 4.1221 - val_accuracy: 0.0724 - val_loss: 11.8920\n",
            "Epoch 22/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 86ms/step - accuracy: 0.2365 - loss: 4.0382 - val_accuracy: 0.0705 - val_loss: 12.2463\n",
            "Epoch 23/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 85ms/step - accuracy: 0.2491 - loss: 3.9554 - val_accuracy: 0.0707 - val_loss: 12.6161\n",
            "Epoch 24/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.2594 - loss: 3.8739 - val_accuracy: 0.0695 - val_loss: 13.0948\n",
            "Epoch 25/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.2674 - loss: 3.8097 - val_accuracy: 0.0677 - val_loss: 13.2710\n",
            "Epoch 26/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.2780 - loss: 3.7341 - val_accuracy: 0.0696 - val_loss: 13.7946\n",
            "Epoch 27/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 87ms/step - accuracy: 0.2899 - loss: 3.6542 - val_accuracy: 0.0679 - val_loss: 14.1161\n",
            "Epoch 28/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 85ms/step - accuracy: 0.3011 - loss: 3.6017 - val_accuracy: 0.0670 - val_loss: 14.4706\n",
            "Epoch 29/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 87ms/step - accuracy: 0.3100 - loss: 3.5462 - val_accuracy: 0.0678 - val_loss: 14.8024\n",
            "Epoch 30/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 85ms/step - accuracy: 0.3170 - loss: 3.4962 - val_accuracy: 0.0663 - val_loss: 15.0698\n",
            "Epoch 31/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 87ms/step - accuracy: 0.3280 - loss: 3.4290 - val_accuracy: 0.0643 - val_loss: 15.1943\n",
            "Epoch 32/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 85ms/step - accuracy: 0.3348 - loss: 3.3694 - val_accuracy: 0.0632 - val_loss: 15.7889\n",
            "Epoch 33/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 86ms/step - accuracy: 0.3436 - loss: 3.3299 - val_accuracy: 0.0638 - val_loss: 16.0927\n",
            "Epoch 34/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 86ms/step - accuracy: 0.3492 - loss: 3.2877 - val_accuracy: 0.0625 - val_loss: 16.3287\n",
            "Epoch 35/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 85ms/step - accuracy: 0.3560 - loss: 3.2354 - val_accuracy: 0.0638 - val_loss: 16.5310\n",
            "Epoch 36/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 86ms/step - accuracy: 0.3676 - loss: 3.1735 - val_accuracy: 0.0627 - val_loss: 16.8574\n",
            "Epoch 37/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 85ms/step - accuracy: 0.3726 - loss: 3.1330 - val_accuracy: 0.0609 - val_loss: 16.9845\n",
            "Epoch 38/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 85ms/step - accuracy: 0.3808 - loss: 3.0855 - val_accuracy: 0.0616 - val_loss: 17.4145\n",
            "Epoch 39/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.3887 - loss: 3.0488 - val_accuracy: 0.0605 - val_loss: 17.6279\n",
            "Epoch 40/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 86ms/step - accuracy: 0.3949 - loss: 2.9996 - val_accuracy: 0.0634 - val_loss: 17.9477\n",
            "Epoch 41/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 85ms/step - accuracy: 0.3999 - loss: 2.9608 - val_accuracy: 0.0610 - val_loss: 17.9941\n",
            "Epoch 42/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 86ms/step - accuracy: 0.4100 - loss: 2.9198 - val_accuracy: 0.0601 - val_loss: 18.5916\n",
            "Epoch 43/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 86ms/step - accuracy: 0.4135 - loss: 2.8864 - val_accuracy: 0.0603 - val_loss: 18.7660\n",
            "Epoch 44/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 85ms/step - accuracy: 0.4225 - loss: 2.8374 - val_accuracy: 0.0616 - val_loss: 19.1917\n",
            "Epoch 45/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.4280 - loss: 2.8085 - val_accuracy: 0.0600 - val_loss: 19.1805\n",
            "Epoch 46/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.4345 - loss: 2.7573 - val_accuracy: 0.0597 - val_loss: 19.4474\n",
            "Epoch 47/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.4412 - loss: 2.7246 - val_accuracy: 0.0571 - val_loss: 19.7172\n",
            "Epoch 48/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 85ms/step - accuracy: 0.4512 - loss: 2.6748 - val_accuracy: 0.0610 - val_loss: 19.9618\n",
            "Epoch 49/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.4559 - loss: 2.6455 - val_accuracy: 0.0589 - val_loss: 20.2474\n",
            "Epoch 50/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.4630 - loss: 2.6150 - val_accuracy: 0.0569 - val_loss: 20.3708\n",
            "Epoch 51/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.4685 - loss: 2.5757 - val_accuracy: 0.0562 - val_loss: 20.6509\n",
            "Epoch 52/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.4714 - loss: 2.5517 - val_accuracy: 0.0571 - val_loss: 20.8723\n",
            "Epoch 53/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.4774 - loss: 2.5175 - val_accuracy: 0.0585 - val_loss: 21.2016\n",
            "Epoch 54/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.4858 - loss: 2.4776 - val_accuracy: 0.0574 - val_loss: 21.2510\n",
            "Epoch 55/55\n",
            "\u001b[1m973/973\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 86ms/step - accuracy: 0.4883 - loss: 2.4580 - val_accuracy: 0.0564 - val_loss: 21.5379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained and saved as 'lstm_poetry_model.h5'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Step 1: Load the Trained Model\n",
        "model = tf.keras.models.load_model(\"lstm_poetry_model.h5\")\n",
        "\n",
        "# Fix the Warning: Recompile the Model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
        "\n",
        "# Step 2: Load the Tokenizer\n",
        "data_path = \"Roman-Urdu-Poetry.csv\"  # Ensure this is the same dataset used before\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Combine all poetry to recreate the tokenizer\n",
        "all_poetry = \" \".join(df[\"Poetry\"].astype(str).tolist()).lower()\n",
        "\n",
        "# Tokenize again (ensure consistency with training)\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([all_poetry])\n",
        "\n",
        "# Get sequence length from training\n",
        "sequence_length = 10  # Ensure this matches the training sequence length\n",
        "\n",
        "# âœ… Step 3: Function to Generate Poetry with Diversity\n",
        "def generate_poetry(seed_text, next_words, model, tokenizer, sequence_length, temperature=1.0):\n",
        "    generated_words = set()  # Store generated words to avoid excessive repetition\n",
        "\n",
        "    for _ in range(next_words):\n",
        "        # Convert seed text to numerical tokens\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=sequence_length, padding='pre')\n",
        "\n",
        "        # Predict next word probabilities\n",
        "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
        "\n",
        "        # Apply temperature scaling\n",
        "        predicted_probs = np.log(predicted_probs + 1e-8) / temperature  # Avoid log(0)\n",
        "        predicted_probs = np.exp(predicted_probs) / np.sum(np.exp(predicted_probs))  # Softmax\n",
        "\n",
        "        # Sample the next word instead of always choosing the highest probability\n",
        "        predicted_word_index = np.random.choice(len(predicted_probs), p=predicted_probs)\n",
        "\n",
        "        # Convert token ID back to word\n",
        "        next_word = None\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_word_index:\n",
        "                next_word = word\n",
        "                break\n",
        "\n",
        "        # If no valid word is found, stop generation\n",
        "        if not next_word or next_word in generated_words:\n",
        "            continue  # Skip repeated words\n",
        "\n",
        "        generated_words.add(next_word)\n",
        "        seed_text += \" \" + next_word\n",
        "\n",
        "    return seed_text\n",
        "\n",
        "# âœ… Step 4: Generate Poetry\n",
        "seed_text = \"muj se pehli se mohabbat\"  # Provide some starting words\n",
        "generated_poetry = generate_poetry(seed_text, 50, model, tokenizer, sequence_length, temperature=0.8)\n",
        "\n",
        "print(\"ğŸ“ Generated Poetry:\\n\", generated_poetry)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W07Q5KKT9HwT",
        "outputId": "07dfc13e-ad43-4563-a2a7-6b27d8bfff51"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Generated Poetry:\n",
            " muj se pehli se mohabbat sunÄ hai hÄ« paanÄ« haiÃ± kaam husn jis ye se ko ki nahÄ«Ã± gayÄ maiÃ± ÄzÄd thÄ« kÄ« nigÄh bhÄ« supurd aur 'farÄz' firÄq e vo jÄntÄ uchatte\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RHy9iX127eXv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T5hqLLUM7iRb"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}